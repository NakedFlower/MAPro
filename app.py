from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Optional, List
import os
from sqlalchemy import create_engine, text
from sqlalchemy.engine import Engine
from dotenv import load_dotenv
import re
from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline
import torch

# AI ëª¨ë¸ ë¡œë“œ (ì•± ì‹œì‘ ì‹œ ë¡œë“œ)
MODEL_NAME = "klue/roberta-base"
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=7)
model.eval()

# NER íŒŒì´í”„ë¼ì¸ ë¡œë“œ (ì§€ì—­ëª… ì¶”ì¶œìš©)
try:
    # í•œêµ­ì–´ NER ëª¨ë¸ ì‹œë„
    ner_pipeline = pipeline("ner", model="klue/roberta-base", aggregation_strategy="simple")
except:
    try:
        # ì˜ì–´ NER ëª¨ë¸ë¡œ í´ë°±
        ner_pipeline = pipeline("ner", model="dbmdz/bert-large-cased-finetuned-conll03-english", aggregation_strategy="simple")
    except:
        # ìµœì¢… í´ë°±: ê¸°ë³¸ BERT ëª¨ë¸
        ner_pipeline = pipeline("ner", aggregation_strategy="simple")

class ChatRequest(BaseModel):
    message: str


class ChatResponse(BaseModel):
    reply: str
    places: list | None = None


app = FastAPI(title="MAPro Chat API", version="0.1.0")
# ê³µìš© ë„ì›€ë§ ë©”ì‹œì§€
HELP_MESSAGE = (
    "ì…ë ¥ì´ ë„ˆë¬´ ê°„ë‹¨í•´ìš”! ğŸ˜…\n\n"
    "ğŸ’¡ ì˜¬ë°”ë¥¸ ì…ë ¥ ì˜ˆì‹œ:\n"
    "â€¢ \"ê°•ë‚¨êµ¬ ë¶„ìœ„ê¸°ì¢‹ì€ ì¹´í˜\"\n"
    "â€¢ \"íŒêµ 24ì‹œê°„ í¸ì˜ì \"\n"

    "ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ë§¤ì¥ ì¢…ë¥˜:\n"
    "ìŒì‹ì , ì¹´í˜, í¸ì˜ì , ì•½êµ­, í˜¸í…”, í—¤ì–´ìƒµ, ë³‘ì›\n\n"
)


def is_low_quality_input(text: str) -> bool:
    """ì˜ë¯¸ ì—†ëŠ” ì…ë ¥(ê¸°í˜¸ë§Œ, ë„ˆë¬´ ì§§ìŒ ë“±)ì„ íŒë³„."""
    if not text:
        return True
    # ê³µë°± ì œê±° í›„ ì˜ìˆ«ì/í•œê¸€ë§Œ ë‚¨ê¹€
    cleaned = re.sub(r"[^0-9A-Za-zê°€-í£]", "", text)
    # ì „ë¶€ ê¸°í˜¸ì´ê±°ë‚˜ ìœ íš¨ ê¸€ì ìˆ˜ê°€ 2 ë¯¸ë§Œ
    if len(cleaned) < 2:
        return True
    # í•œê¸€/ì˜ë¬¸/ìˆ«ì ì¤‘ í•˜ë‚˜ë„ ì—†ìœ¼ë©´ ë¬´ì˜ë¯¸
    if not re.search(r"[0-9A-Za-zê°€-í£]", text):
        return True
    return False


# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"], # ëª¨ë“  origin í—ˆìš©
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# chat_endpoint
@app.post("/chat", response_model=ChatResponse)
def chat_endpoint(req: ChatRequest):
    user_message = (req.message or "").strip()
    if not user_message:
        return ChatResponse(reply="ë©”ì‹œì§€ê°€ ë¹„ì–´ ìˆì–´ìš”.")

    try:
        # 0) ì…ë ¥ ìœ íš¨ì„± 1ì°¨ í•„í„°
        if is_low_quality_input(user_message):
            return ChatResponse(reply=HELP_MESSAGE, places=None)

        # 1) NLP: ì¹´í…Œê³ ë¦¬/íŠ¹ì„±/ì§€ì—­ ì¶”ì¶œ
        extracted = extract_query(user_message)
        
        # 2) í•„ìˆ˜ ì •ë³´(ì§€ì—­, ì¹´í…Œê³ ë¦¬) ê²€ì¦ ê°•í™”
        location = extracted.get("location")
        category = extracted.get("category")

        if not location or not category:
            # ì§€ì—­ì´ë‚˜ ì¹´í…Œê³ ë¦¬ ì¤‘ í•˜ë‚˜ë¼ë„ ì—†ìœ¼ë©´ ë” êµ¬ì²´ì ì¸ ì§ˆë¬¸ìœ¼ë¡œ ì‘ë‹µ
            if not location and not category:
                # ë‘˜ ë‹¤ ì—†ëŠ” ê²½ìš°: ê¸°ì¡´ ë„ì›€ë§
                return ChatResponse(reply=HELP_MESSAGE, places=None)
            elif not location:
                # ì§€ì—­ì´ ì—†ëŠ” ê²½ìš°
                return ChatResponse(reply=f"ì–´ëŠ ì§€ì—­ì—ì„œ {category}ì„(ë¥¼) ì°¾ìœ¼ì‹œë‚˜ìš”? ğŸ¤”\nì˜ˆ: \"ê°•ë‚¨ {category}\"", places=None)
            else: # not category
                # ì¹´í…Œê³ ë¦¬ê°€ ì—†ëŠ” ê²½ìš°
                return ChatResponse(reply=f"'{location}'ì—ì„œ ì–´ë–¤ ì¥ì†Œë¥¼ ì°¾ìœ¼ì„¸ìš”? ğŸ‘€\n(ì˜ˆ: ìŒì‹ì , ì¹´í˜, ì•½êµ­ ë“±)", places=None)
        

        # 3) DB ì¡°íšŒ 
        matched_places = query_places(extracted)
        
        # 4) ì‘ë‹µ ìƒì„±
        if matched_places:
            reply_text = build_reply(extracted, matched_places)
            # places ë¦¬ìŠ¤íŠ¸ì—ëŠ” DBì—ì„œ ë°›ì€ ëª¨ë“  ì •ë³´ë¥¼ í¬í•¨í•˜ì—¬ í”„ë¡ íŠ¸ì—ì„œ í™œìš©í•  ìˆ˜ ìˆë„ë¡ ê°œì„ 
            return ChatResponse(reply=reply_text, places=matched_places[:5])
        else:
            return ChatResponse(reply="ì¡°ê±´ì— ë§ëŠ” ë§¤ì¥ì„ ì°¾ì§€ ëª»í–ˆì–´ìš”. ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ì‹œë„í•´ ë³´ì‹œê² ì–´ìš”?", places=None)
            
    except Exception as e:
        print(f"ì±„íŒ… ì—”ë“œí¬ì¸íŠ¸ ì˜¤ë¥˜: {e}") # ë””ë²„ê¹…ì„ ìœ„í•œ ë¡œê·¸ ì¶”ê°€
        return ChatResponse(reply="ì„œë²„ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.", places=None)


@app.get("/health")
def health_check():
    try:
        # DB ì—°ê²° í…ŒìŠ¤íŠ¸
        engine = get_db_engine()
        with engine.connect() as conn:
            conn.execute(text("SELECT 1"))
        return {"status": "ok", "database": "connected"}
    except Exception as e:
        return {"status": "error", "database": "disconnected", "error": str(e)}


# ------------------ ì„¤ì •/DB ------------------
load_dotenv()

def get_engine() -> Engine:
    # GCP MySQL Database Configuration
    host = os.getenv("DB_HOST", "mapro.cloud")
    port = os.getenv("DB_PORT", "3306")
    user = os.getenv("DB_USER", "dev")
    password = os.getenv("DB_PASSWORD", "Dev1010**")
    name = os.getenv("DB_NAME", "mapro")
    url = f"mysql+pymysql://{user}:{password}@{host}:{port}/{name}?charset=utf8mb4"
    return create_engine(url, pool_pre_ping=True)

ENGINE: Optional[Engine] = None

def get_db_engine() -> Engine:
    global ENGINE
    if ENGINE is None:
        ENGINE = get_engine()
    return ENGINE


# ------------------ AI ëª¨ë¸ ì„¤ì • ------------------
# ì¹´í…Œê³ ë¦¬ ë¼ë²¨ ì •ì˜
CATEGORY_LABELS = ["ìŒì‹ì ", "ì¹´í˜", "í¸ì˜ì ", "ì•½êµ­", "í˜¸í…”", "í—¤ì–´ìƒµ", "ë³‘ì›"]

# ------------------ AI ê¸°ë°˜ NLP ------------------
def normalize(text: str) -> str:
    return text.strip()


def classify_category_with_ai(text: str) -> str:
    """AI ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜"""
    try:
        # í…ìŠ¤íŠ¸ í† í¬ë‚˜ì´ì§•
        inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True, max_length=512)
        
        # ëª¨ë¸ ì˜ˆì¸¡
        with torch.no_grad():
            outputs = model(**inputs)
            predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)
            predicted_class_id = torch.argmax(predictions, dim=-1).item()
            confidence = predictions[0][predicted_class_id].item()
        
        # ì‹ ë¢°ë„ê°€ ë‚®ìœ¼ë©´ None ë°˜í™˜
        if confidence < 0.3:
            return None
            
        return CATEGORY_LABELS[predicted_class_id]
    except Exception as e:
        print(f"AI ë¶„ë¥˜ ì˜¤ë¥˜: {e}")
        return None


def extract_features_with_ai(text: str, category: str) -> list:
    try:
        # ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜ íŠ¹ì„± ì¶”ì¶œ (AI ëª¨ë¸ì´ ì—†ìœ¼ë¯€ë¡œ)
        features = []
        
        # ì¹´í…Œê³ ë¦¬ë³„ íŠ¹ì„± í‚¤ì›Œë“œ (ì •í™•í•œ feature ëª©ë¡)
        feature_keywords = {
            "ìŒì‹ì ": ["ìœ ì•„ì˜ì", "í˜¼ë°¥", "ìƒˆë¡œì˜¤í”ˆ", "ë°ì´íŠ¸", "ë…¸í‚¤ì¦ˆì¡´", "ì§€ì—­í™”í", "ì£¼ì°¨", "ì¸ê¸°ë§ì€"],
            "ì¹´í˜": ["í¸í•œì¢Œì„", "ì¹´ê³µ", "ë…¸í‚¤ì¦ˆì¡´", "ë¶„ìœ„ê¸°ì¢‹ì€", "ì¸í…Œë¦¬ì–´", "ë””ì €íŠ¸", "ì¡°ìš©í•œ", "24ì‹œê°„"],
            "í¸ì˜ì ": ["ì•¼ì™¸ì¢Œì„", "ATM", "ì·¨ì‹ê³µê°„"],
            "ì•½êµ­": ["ì¹œì ˆ", "ë¹„ì²˜ë°©ì˜ì•½í’ˆ"],
            "í˜¸í…”": ["ìŠ¤íŒŒ/ì›”í’€/ìš•ì¡°", "ë°˜ë ¤ë™ë¬¼ ë™ë°˜", "ì£¼ì°¨ê°€ëŠ¥", "ì „ê¸°ì°¨ ì¶©ì „", "ê°ì‹¤ê¸ˆì—°", "OTT", "ìˆ˜ì˜ì¥", "ê°ì‹¤ë‚´ PC", "ë°”ë² í", "ì¡°ì‹"],
            "í—¤ì–´ìƒµ": ["ì¸ê¸°ë§ì€", "ì¿ í°ë©¤ë²„ì‹­", "ì˜ˆì•½í•„ìˆ˜"],
            "ë³‘ì›": ["ì‘ê¸‰ì‹¤", "ì „ë¬¸ì˜", "ì•¼ê°„ì§„ë£Œ"]
        }
        
        if category in feature_keywords:
            for feature in feature_keywords[category]:
                if feature in text:
                    features.append(feature)
        
        return features
    except Exception as e:
        print(f"íŠ¹ì„± ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        return []


def extract_location_with_ai(text: str) -> str:
    """ìˆœìˆ˜ Transformers NERì„ ì‚¬ìš©í•˜ì—¬ ìœ„ì¹˜ ì •ë³´ ì¶”ì¶œ"""
    try:
        # NER íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ì—”í‹°í‹° ì¶”ì¶œ
        entities = ner_pipeline(text)
        
        # ìœ„ì¹˜ ê´€ë ¨ ì—”í‹°í‹° í•„í„°ë§ ë° ì •ë¦¬
        location_entities = []
        for entity in entities:
            # LOC, GPE ë¼ë²¨ì„ ìœ„ì¹˜ë¡œ ê°„ì£¼ (ORG ì œì™¸)
            if entity['entity_group'] in ['LOC', 'GPE']:
                entity_text = entity['word'].strip()
                # ê¸°ë³¸ì ì¸ ê¸¸ì´ í•„í„°ë§ë§Œ ì ìš©
                if len(entity_text) >= 2:
                    location_entities.append({
                        'text': entity_text,
                        'score': entity['score'],
                        'label': entity['entity_group']
                    })
        
        if not location_entities:
            return None
        
        # ì‹ ë¢°ë„ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ê°€ì¥ ë†’ì€ ì‹ ë¢°ë„ì˜ ìœ„ì¹˜ ë°˜í™˜
        location_entities.sort(key=lambda x: x['score'], reverse=True)
        return location_entities[0]['text']
        
    except Exception as e:
        print(f"ìœ„ì¹˜ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        return None


def extract_query(text: str) -> dict:
    """AI ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì¿¼ë¦¬ ì¶”ì¶œ"""
    t = normalize(text)
    
    # AI ëª¨ë¸ë¡œ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
    category = classify_category_with_ai(t)
    
    # AIë¡œ íŠ¹ì„± ì¶”ì¶œ
    features = extract_features_with_ai(t, category) if category else []
    
    # AIë¡œ ìœ„ì¹˜ ì¶”ì¶œ
    location = extract_location_with_ai(t)
    
    return {"category": category, "features": features, "location": location}


# ------------------ DB ì¡°íšŒ ------------------
def query_places(query: dict) -> list:
    try:
        engine = get_db_engine()
        
        # chat_endpointì—ì„œ ê²€ì¦ì„ ê±°ì³¤ìœ¼ë¯€ë¡œ categoryì™€ locationì€ í•­ìƒ ì¡´ì¬
        category = query["category"]
        location = query["location"]
        features = query.get("features") or []

        # WHERE ì ˆì„ ëª…ì‹œì ìœ¼ë¡œ êµ¬ì„±
        where_clauses = [
            "category = :category",
            "location LIKE :location"
        ]
        params = {
            "category": category,
            "location": f"%{location}%"
        }

        # SQL ì¿¼ë¦¬ ìƒì„±
        base_sql = "SELECT place_id, category, name, location, feature FROM place WHERE "
        sql_query = base_sql + " AND ".join(where_clauses)
        sql_query += " ORDER BY updated_at DESC, created_at DESC LIMIT 30"
        
        sql = text(sql_query)
        
        with engine.connect() as conn:
            rows = [dict(r._mapping) for r in conn.execute(sql, params)]

        if not rows:
            return []

        # íŠ¹ì„±(feature) ì ìˆ˜ ê¸°ë°˜ìœ¼ë¡œ Pythonì—ì„œ ì¬ì •ë ¬
        def score(place):
            place_features = (place.get("feature") or "").split(",")
            place_features = [f.strip() for f in place_features if f.strip()]
            
            # ê²€ìƒ‰ì–´ì— í¬í•¨ëœ featureê°€ ë§¤ì¥ì˜ featureì— ì–¼ë§ˆë‚˜ ìˆëŠ”ì§€ ê³„ì‚°
            match_count = sum(1 for f in features if f in place_features)
            return match_count

        rows.sort(key=score, reverse=True)
        return rows[:5]
        
    except Exception as e:
        print(f"DB ì¡°íšŒ ì˜¤ë¥˜: {e}") # ë””ë²„ê¹…ì„ ìœ„í•œ ë¡œê·¸ ì¶”ê°€
        return []


# ------------------ ì‘ë‹µ ìƒì„± ------------------
def build_reply(query: dict, places: list) -> str:
    parts = []
    if query.get("location"):
        parts.append(query['location'])
    if query.get("category"):
        parts.append(query['category'])
    if query.get("features"):
        parts.append(", ".join(query["features"]))

    cond = " ".join(parts) if parts else "ìš”ì²­í•˜ì‹ "
    names = ", ".join([p["name"] for p in places[:5]])
    
    if len(places) > 0:
        return f"{cond} ì¡°ê±´ìœ¼ë¡œ {len(places)}ê³³ì„ ì°¾ì•˜ì–´ìš”"
    else:
        return f"{cond} ì¡°ê±´ì— ë§ëŠ” ë§¤ì¥ì„ ì°¾ì§€ ëª»í–ˆì–´ìš”. ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ì‹œë„í•´ ë³´ì‹œê² ì–´ìš”?"
