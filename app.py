from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Optional, List
import os
from sqlalchemy import create_engine, text
from sqlalchemy.engine import Engine
from dotenv import load_dotenv
import re
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch

# AI ëª¨ë¸ ë¡œë“œ (ì•± ì‹œì‘ ì‹œ ë¡œë“œ)
MODEL_NAME = "klue/roberta-base"
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=7)
model.eval()

class ChatRequest(BaseModel):
    message: str


class ChatResponse(BaseModel):
    reply: str
    places: list | None = None


app = FastAPI(title="MAPro Chat API", version="0.1.0")
# ê³µìš© ë„ì›€ë§ ë©”ì‹œì§€
HELP_MESSAGE = (
    "ì…ë ¥ì´ ë„ˆë¬´ ê°„ë‹¨í•´ìš”! ğŸ˜…\n\n"
    "ğŸ’¡ ì˜¬ë°”ë¥¸ ì…ë ¥ ì˜ˆì‹œ:\n"
    "â€¢ \"ê°•ë‚¨êµ¬ ë¶„ìœ„ê¸°ì¢‹ì€ ì¹´í˜\"\n"
    "â€¢ \"íŒêµ 24ì‹œê°„ í¸ì˜ì \"\n"
    "â€¢ \"ë…¸í‚¤ì¦ˆì¡´ ìŒì‹ì \"\n"
    "â€¢ \"ì£¼ì°¨ê°€ëŠ¥ í˜¸í…”\"\n\n"
    "ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ë§¤ì¥ ì¢…ë¥˜:\n"
    "ìŒì‹ì , ì¹´í˜, í¸ì˜ì , ì•½êµ­, í˜¸í…”, í—¤ì–´ìƒµ, ë³‘ì›\n\n"
    "ğŸ” íŠ¹ì„± í‚¤ì›Œë“œ ì˜ˆì‹œ:\n"
    "ë¶„ìœ„ê¸°ì¢‹ì€, 24ì‹œê°„, ë…¸í‚¤ì¦ˆì¡´, ì£¼ì°¨ê°€ëŠ¥, ì¸ê¸°ë§ì€ ë“±"
)


def is_low_quality_input(text: str) -> bool:
    """ì˜ë¯¸ ì—†ëŠ” ì…ë ¥(ê¸°í˜¸ë§Œ, ë„ˆë¬´ ì§§ìŒ ë“±)ì„ íŒë³„."""
    if not text:
        return True
    # ê³µë°± ì œê±° í›„ ì˜ìˆ«ì/í•œê¸€ë§Œ ë‚¨ê¹€
    cleaned = re.sub(r"[^0-9A-Za-zê°€-í£]", "", text)
    # ì „ë¶€ ê¸°í˜¸ì´ê±°ë‚˜ ìœ íš¨ ê¸€ì ìˆ˜ê°€ 2 ë¯¸ë§Œ
    if len(cleaned) < 2:
        return True
    # í•œê¸€/ì˜ë¬¸/ìˆ«ì ì¤‘ í•˜ë‚˜ë„ ì—†ìœ¼ë©´ ë¬´ì˜ë¯¸
    if not re.search(r"[0-9A-Za-zê°€-í£]", text):
        return True
    return False


# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"], # ëª¨ë“  origin í—ˆìš©
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


@app.post("/chat", response_model=ChatResponse)
def chat_endpoint(req: ChatRequest):
    user_message = (req.message or "").strip()
    if not user_message:
        return ChatResponse(reply="ë©”ì‹œì§€ê°€ ë¹„ì–´ ìˆì–´ìš”.")

    try:
        # 0) ì…ë ¥ ìœ íš¨ì„± 1ì°¨ í•„í„°
        if is_low_quality_input(user_message):
            return ChatResponse(reply=HELP_MESSAGE, places=None)

        # 1) NLP: ì¹´í…Œê³ ë¦¬/íŠ¹ì„±/ì§€ì—­ ì¶”ì¶œ
        extracted = extract_query(user_message)
        
        # ì…ë ¥ ê²€ì¦ ë° ë„ì›€ë§ ì œê³µ
        if not extracted.get("category") and not extracted.get("location"):
            return ChatResponse(reply=HELP_MESSAGE, places=None)
        
        # 2) DB ì¡°íšŒ
        matched_places = query_places(extracted)
        
        # 3) ì‘ë‹µ ìƒì„±
        if matched_places:
            reply_text = build_reply(extracted, matched_places)
            return ChatResponse(reply=reply_text, places=[{"name": p["name"]} for p in matched_places[:5]])
        else:
            return ChatResponse(reply="ì¡°ê±´ì— ë§ëŠ” ë§¤ì¥ì„ ì°¾ì§€ ëª»í–ˆì–´ìš”. ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ì‹œë„í•´ ë³´ì‹œê² ì–´ìš”?", places=None)
            
    except Exception:
        return ChatResponse(reply="ì„œë²„ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.", places=None)


@app.get("/health")
def health_check():
    try:
        # DB ì—°ê²° í…ŒìŠ¤íŠ¸
        engine = get_db_engine()
        with engine.connect() as conn:
            conn.execute(text("SELECT 1"))
        return {"status": "ok", "database": "connected"}
    except Exception as e:
        return {"status": "error", "database": "disconnected", "error": str(e)}


# ------------------ ì„¤ì •/DB ------------------
load_dotenv()

def get_engine() -> Engine:
    # GCP MySQL Database Configuration
    host = os.getenv("DB_HOST", "mapro.cloud")
    port = os.getenv("DB_PORT", "3306")
    user = os.getenv("DB_USER", "dev")
    password = os.getenv("DB_PASSWORD", "Dev1010**")
    name = os.getenv("DB_NAME", "mapro")
    url = f"mysql+pymysql://{user}:{password}@{host}:{port}/{name}?charset=utf8mb4"
    return create_engine(url, pool_pre_ping=True)

ENGINE: Optional[Engine] = None

def get_db_engine() -> Engine:
    global ENGINE
    if ENGINE is None:
        ENGINE = get_engine()
    return ENGINE


# ------------------ AI ëª¨ë¸ ì„¤ì • ------------------
# ì¹´í…Œê³ ë¦¬ ë¼ë²¨ ì •ì˜
CATEGORY_LABELS = ["ìŒì‹ì ", "ì¹´í˜", "í¸ì˜ì ", "ì•½êµ­", "í˜¸í…”", "í—¤ì–´ìƒµ", "ë³‘ì›"]

# ------------------ AI ê¸°ë°˜ NLP ------------------
def normalize(text: str) -> str:
    return text.strip()


def classify_category_with_ai(text: str) -> str:
    """AI ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜"""
    try:
        # í…ìŠ¤íŠ¸ í† í¬ë‚˜ì´ì§•
        inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True, max_length=512)
        
        # ëª¨ë¸ ì˜ˆì¸¡
        with torch.no_grad():
            outputs = model(**inputs)
            predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)
            predicted_class_id = torch.argmax(predictions, dim=-1).item()
            confidence = predictions[0][predicted_class_id].item()
        
        # ì‹ ë¢°ë„ê°€ ë‚®ìœ¼ë©´ None ë°˜í™˜
        if confidence < 0.3:
            return None
            
        return CATEGORY_LABELS[predicted_class_id]
    except Exception as e:
        print(f"AI ë¶„ë¥˜ ì˜¤ë¥˜: {e}")
        return None


def extract_features_with_ai(text: str, category: str) -> list:
    try:
        # ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜ íŠ¹ì„± ì¶”ì¶œ (AI ëª¨ë¸ì´ ì—†ìœ¼ë¯€ë¡œ)
        features = []
        
        # ì¹´í…Œê³ ë¦¬ë³„ íŠ¹ì„± í‚¤ì›Œë“œ (ì •í™•í•œ feature ëª©ë¡)
        feature_keywords = {
            "ìŒì‹ì ": ["ìœ ì•„ì˜ì", "í˜¼ë°¥", "ìƒˆë¡œì˜¤í”ˆ", "ë°ì´íŠ¸", "ë…¸í‚¤ì¦ˆì¡´", "ì§€ì—­í™”í", "ì£¼ì°¨", "ì¸ê¸°ë§ì€"],
            "ì¹´í˜": ["í¸í•œì¢Œì„", "ì¹´ê³µ", "ë…¸í‚¤ì¦ˆì¡´", "ë¶„ìœ„ê¸°ì¢‹ì€", "ì¸í…Œë¦¬ì–´", "ë””ì €íŠ¸", "ì¡°ìš©í•œ", "24ì‹œê°„"],
            "í¸ì˜ì ": ["ì•¼ì™¸ì¢Œì„", "ATM", "ì·¨ì‹ê³µê°„"],
            "ì•½êµ­": ["ì¹œì ˆ", "ë¹„ì²˜ë°©ì˜ì•½í’ˆ"],
            "í˜¸í…”": ["ìŠ¤íŒŒ/ì›”í’€/ìš•ì¡°", "ë°˜ë ¤ë™ë¬¼ ë™ë°˜", "ì£¼ì°¨ê°€ëŠ¥", "ì „ê¸°ì°¨ ì¶©ì „", "ê°ì‹¤ê¸ˆì—°", "OTT", "ìˆ˜ì˜ì¥", "ê°ì‹¤ë‚´ PC", "ë°”ë² í", "ì¡°ì‹"],
            "í—¤ì–´ìƒµ": ["ì¸ê¸°ë§ì€", "ì¿ í°ë©¤ë²„ì‹­", "ì˜ˆì•½í•„ìˆ˜"],
            "ë³‘ì›": ["ì‘ê¸‰ì‹¤", "ì „ë¬¸ì˜", "ì•¼ê°„ì§„ë£Œ"]
        }
        
        if category in feature_keywords:
            for feature in feature_keywords[category]:
                if feature in text:
                    features.append(feature)
        
        return features
    except Exception as e:
        print(f"íŠ¹ì„± ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        return []


def extract_location_with_ai(text: str) -> str:
    """AIë¥¼ ì‚¬ìš©í•˜ì—¬ ìœ„ì¹˜ ì •ë³´ ì¶”ì¶œ"""
    try:
        # ê°„ë‹¨í•œ íŒ¨í„´ ë§¤ì¹­ìœ¼ë¡œ ìœ„ì¹˜ ì¶”ì¶œ
        import re
        
        # ì§€ì—­ëª… íŒ¨í„´ (êµ¬, ë™, ì‹œë¡œ ëë‚˜ëŠ” ë‹¨ì–´)
        location_pattern = r'(\w+(?:êµ¬|ë™|ì‹œ))'
        matches = re.findall(location_pattern, text)
        if matches:
            return matches[0]
        
        # ì£¼ìš” ì§€ì—­ëª…
        common_locations = ["ê°•ë‚¨", "ê°•ë‚¨êµ¬", "ì„œì´ˆ", "ì„œì´ˆêµ¬", "íŒêµ", "ë¶„ë‹¹", "ì¼ì‚°", "íŒŒì£¼", "ìš´ì •", "í™ëŒ€", "ì—¬ì˜ë„", "ì ì‹¤"]
        for loc in common_locations:
            if loc in text:
                return loc
        
        return None
    except Exception as e:
        print(f"ìœ„ì¹˜ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        return None


def extract_query(text: str) -> dict:
    """AI ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì¿¼ë¦¬ ì¶”ì¶œ"""
    t = normalize(text)
    
    # AI ëª¨ë¸ë¡œ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
    category = classify_category_with_ai(t)
    
    # AIë¡œ íŠ¹ì„± ì¶”ì¶œ
    features = extract_features_with_ai(t, category) if category else []
    
    # AIë¡œ ìœ„ì¹˜ ì¶”ì¶œ
    location = extract_location_with_ai(t)
    
    return {"category": category, "features": features, "location": location}


# ------------------ DB ì¡°íšŒ ------------------
def query_places(query: dict) -> list:
    try:
        engine = get_db_engine()
        
        category = query.get("category")
        features = query.get("features") or []
        location = query.get("location")

        # ê¸°ë³¸ WHERE ì ˆ êµ¬ì„±
        where = []
        params = {}
        if category:
            where.append("category = :category")
            params["category"] = category
        if location:
            where.append("location LIKE :location")
            params["location"] = f"%{location}%"

        base_sql = "SELECT place_id, category, name, location, feature FROM place"
        if where:
            base_sql += " WHERE " + " AND ".join(where)

        # ìš°ì„  í›„ë³´ 30ê°œ ì¡°íšŒ
        sql = text(base_sql + " ORDER BY updated_at DESC, created_at DESC LIMIT 30")
        
        with engine.connect() as conn:
            rows = [dict(r._mapping) for r in conn.execute(sql, params)]

        if not rows:
            return []

        # íŠ¹ì„± ì ìˆ˜ ê¸°ë°˜ ì •ë ¬
        def score(row):
            row_features = (row.get("feature") or "").split(",")
            row_features = [rf.strip() for rf in row_features if rf.strip()]
            return sum(1 for f in features if f in row_features)

        rows.sort(key=score, reverse=True)
        return rows[:5]
        
    except Exception:
        return []  # DB ì˜¤ë¥˜ ì‹œ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜


# ------------------ ì‘ë‹µ ìƒì„± ------------------
def build_reply(query: dict, places: list) -> str:
    parts = []
    if query.get("location"):
        parts.append(query['location'])
    if query.get("category"):
        parts.append(query['category'])
    if query.get("features"):
        parts.append(", ".join(query["features"]))

    cond = " ".join(parts) if parts else "ìš”ì²­í•˜ì‹ "
    names = ", ".join([p["name"] for p in places[:5]])
    
    if len(places) > 0:
        return f"{cond} ì¡°ê±´ìœ¼ë¡œ {len(places)}ê³³ì„ ì°¾ì•˜ì–´ìš”"
    else:
        return f"{cond} ì¡°ê±´ì— ë§ëŠ” ë§¤ì¥ì„ ì°¾ì§€ ëª»í–ˆì–´ìš”. ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ì‹œë„í•´ ë³´ì‹œê² ì–´ìš”?"
